{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in all words\n",
    "words = open('names.txt','r').read().splitlines()\n",
    "words[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '.', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z'}\n"
     ]
    }
   ],
   "source": [
    "#Building the vocabulary of characters and mappings to integrers\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "print(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the dataset\n",
    "\n",
    "block_size = 3    #context length : characters taken to predict the next one\n",
    "X, Y = [], []\n",
    "\n",
    "for w in words:\n",
    "\n",
    "    #print(w)\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "        ix = stoi[ch]\n",
    "        X.append(context)\n",
    "        Y.append(ix)\n",
    "        #print(''.join(itos[i] for i in context), '---->', itos[ix])\n",
    "        context = context[1:] + [ix]      #crop and append\n",
    "\n",
    "X = torch.tensor(X)\n",
    "Y = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([228146, 3]), torch.Size([228146]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((27,2), generator=g)\n",
    "W1 = torch.randn((6,100), generator=g)\n",
    "b1 = torch.rand(100, generator=g)\n",
    "W2 = torch.randn((100,27), generator=g)\n",
    "b2 = torch.rand(27, generator=g)\n",
    "parameters = [C, W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3481"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.nelement() for p in parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.098272323608398\n",
      "4.584640026092529\n",
      "4.128853797912598\n",
      "3.7277801036834717\n",
      "3.3761425018310547\n",
      "3.0636894702911377\n",
      "2.7858705520629883\n",
      "2.541958808898926\n",
      "2.3299779891967773\n",
      "2.1440341472625732\n",
      "1.9787911176681519\n",
      "1.8316885232925415\n",
      "1.702017903327942\n",
      "1.5883747339248657\n",
      "1.4876667261123657\n",
      "1.3966777324676514\n",
      "1.3133565187454224\n",
      "1.2367783784866333\n",
      "1.166650414466858\n",
      "1.102752447128296\n",
      "1.044610619544983\n",
      "0.9915212392807007\n",
      "0.9426817297935486\n",
      "0.8972891569137573\n",
      "0.8546355962753296\n",
      "0.8141732811927795\n",
      "0.7755289673805237\n",
      "0.738495945930481\n",
      "0.7030269503593445\n",
      "0.66923987865448\n",
      "0.6374204754829407\n",
      "0.6079904437065125\n",
      "0.5813909769058228\n",
      "0.5578778386116028\n",
      "0.5373654365539551\n",
      "0.5194960236549377\n",
      "0.5038795471191406\n",
      "0.4902423024177551\n",
      "0.4784000515937805\n",
      "0.4681757390499115\n",
      "0.4593650698661804\n",
      "0.4517451524734497\n",
      "0.4451042711734772\n",
      "0.4392598271369934\n",
      "0.43406492471694946\n",
      "0.42940449714660645\n",
      "0.4251899719238281\n",
      "0.42135217785835266\n",
      "0.41783690452575684\n",
      "0.4146006107330322\n",
      "0.41160839796066284\n",
      "0.40883103013038635\n",
      "0.4062448740005493\n",
      "0.4038296639919281\n",
      "0.4015681743621826\n",
      "0.3994458317756653\n",
      "0.39744997024536133\n",
      "0.3955696225166321\n",
      "0.3937950134277344\n",
      "0.39211761951446533\n",
      "0.39052993059158325\n",
      "0.3890253007411957\n",
      "0.38759729266166687\n",
      "0.38624054193496704\n",
      "0.3849502503871918\n",
      "0.3837219774723053\n",
      "0.382551372051239\n",
      "0.38143476843833923\n",
      "0.38036879897117615\n",
      "0.3793502449989319\n",
      "0.37837615609169006\n",
      "0.377443790435791\n",
      "0.3765508532524109\n",
      "0.3756949305534363\n",
      "0.3748738765716553\n",
      "0.37408575415611267\n",
      "0.3733287751674652\n",
      "0.3726010024547577\n",
      "0.3719009757041931\n",
      "0.37122732400894165\n",
      "0.3705785572528839\n",
      "0.36995330452919006\n",
      "0.3693503737449646\n",
      "0.3687688112258911\n",
      "0.36820724606513977\n",
      "0.3676649034023285\n",
      "0.36714082956314087\n",
      "0.36663398146629333\n",
      "0.36614373326301575\n",
      "0.36566925048828125\n",
      "0.36520975828170776\n",
      "0.364764541387558\n",
      "0.36433300375938416\n",
      "0.3639145493507385\n",
      "0.3635086417198181\n",
      "0.36311450600624084\n",
      "0.36273193359375\n",
      "0.36236029863357544\n",
      "0.3619990050792694\n",
      "0.36164790391921997\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100):\n",
    "    #Forward pass\n",
    "    emb = C[X]          #[32,3,2]\n",
    "    h = torch.tanh(emb.view(-1,6) @ W1 + b1)            #(32,100)\n",
    "    logits = h @ W2 + b2                                #(32,27)\n",
    "    # counts = logits.exp()\n",
    "    # prob = counts / counts.sum(1, keepdims=True)\n",
    "    # loss = -prob[torch.arange(32), Y].log().mean()\n",
    "    loss = F.cross_entropy(logits, Y)\n",
    "    #print(loss.item())\n",
    "\n",
    "    #backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward()\n",
    "    #update\n",
    "    for p in parameters:\n",
    "        p.data += -0.1 * p.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
